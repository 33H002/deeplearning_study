{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49a6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model.mlp import MLP\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c35d3ac",
   "metadata": {},
   "source": [
    "#### Set Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae5d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 333\n",
    "seed_everything(SEED)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 10000\n",
    "PATIENCE = 20\n",
    "\n",
    "SAVE_PATH = '.'\n",
    "RUN_NAME = 'MLP-regression'\n",
    "WANDB_PRJ = 'public'\n",
    "\n",
    "WANDB_CONFIG = {\n",
    "    'seed': SEED,\n",
    "    'model': RUN_NAME,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,  \n",
    "}\n",
    "\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "        os.makedirs(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b8bdd3",
   "metadata": {},
   "source": [
    "#### Load Dataset and Make Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8708bafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>0.073350</td>\n",
       "      <td>-0.872264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>-0.207948</td>\n",
       "      <td>0.409724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>-0.207071</td>\n",
       "      <td>-0.091855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>0.651256</td>\n",
       "      <td>-0.071812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>-0.517023</td>\n",
       "      <td>2.178881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleCondition_nan</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalePrice</th>\n",
       "      <td>12.247694</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0          1\n",
       "MSSubClass              0.073350  -0.872264\n",
       "LotFrontage            -0.207948   0.409724\n",
       "LotArea                -0.207071  -0.091855\n",
       "OverallQual             0.651256  -0.071812\n",
       "OverallCond            -0.517023   2.178881\n",
       "...                          ...        ...\n",
       "SaleCondition_Family    0.000000   0.000000\n",
       "SaleCondition_Normal    1.000000   1.000000\n",
       "SaleCondition_Partial   0.000000   0.000000\n",
       "SaleCondition_nan       0.000000   0.000000\n",
       "SalePrice              12.247694  12.109011\n",
       "\n",
       "[332 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./sample_datasets/house-prices/preprocessed.csv')\n",
    "df.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac77eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop('SalePrice', axis=1).values, df['SalePrice'].values\n",
    "\n",
    "trn_data, val_data, trn_label, val_label = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "trn_ds, val_ds = list(map(lambda x, y: TensorDataset(torch.tensor(x, dtype=torch.float), torch.tensor(y, dtype=torch.float)), \n",
    "                          [trn_data, val_data], [trn_label, val_label]))\n",
    "trn_dl, val_dl = list(map(lambda x, y: DataLoader(x, batch_size=BATCH_SIZE, num_workers=cpu_count(), shuffle=y, drop_last=True), \n",
    "                          [trn_ds, val_ds], [True, False]))\n",
    "\n",
    "datasets = {'train' : trn_ds, 'valid': val_ds}\n",
    "dataloaders = {'train': trn_dl, 'valid': val_dl}\n",
    "\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'valid']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f1ff0b",
   "metadata": {},
   "source": [
    "#### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f240350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (activation): GELU(approximate='none')\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=331, out_features=128, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (8): GELU(approximate='none')\n",
      "    (9): Dropout(p=0.1, inplace=False)\n",
      "    (10): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (11): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (12): GELU(approximate='none')\n",
      "    (13): Dropout(p=0.1, inplace=False)\n",
      "    (14): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP(in_features=331, hidden_dim=128, out_features=1, num_layers=4, dropout=0.1)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0, last_epoch=-1, verbose=False)\n",
    "criterion = nn.MSELoss()\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a208b466",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb3313e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m33h002\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20230403_131534-mfifz7a4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/33h002/public/runs/mfifz7a4' target=\"_blank\">MLP-regression</a></strong> to <a href='https://wandb.ai/33h002/public' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/33h002/public' target=\"_blank\">https://wandb.ai/33h002/public</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/33h002/public/runs/mfifz7a4' target=\"_blank\">https://wandb.ai/33h002/public/runs/mfifz7a4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model running on cuda\n",
      "epoch 10 train | Loss: 30.7220\n",
      "epoch 10 valid | Loss: 27.3417\n",
      "epoch 20 train | Loss: 9.8301\n",
      "epoch 20 valid | Loss: 8.2137\n",
      "epoch 30 train | Loss: 2.9762\n",
      "epoch 30 valid | Loss: 2.1576\n",
      "epoch 40 train | Loss: 1.2122\n",
      "epoch 40 valid | Loss: 0.7487\n",
      "epoch 50 train | Loss: 0.9577\n",
      "epoch 50 valid | Loss: 0.4516\n",
      "epoch 60 train | Loss: 0.8723\n",
      "epoch 60 valid | Loss: 0.4157\n",
      "epoch 70 train | Loss: 0.8357\n",
      "epoch 70 valid | Loss: 0.3806\n",
      "epoch 80 train | Loss: 0.6436\n",
      "epoch 80 valid | Loss: 0.2233\n",
      "epoch 90 train | Loss: 0.5134\n",
      "epoch 90 valid | Loss: 0.1514\n",
      "epoch 100 train | Loss: 0.5166\n",
      "epoch 100 valid | Loss: 0.1427\n",
      "epoch 110 train | Loss: 0.3871\n",
      "epoch 110 valid | Loss: 0.0451\n",
      "epoch 120 train | Loss: 0.4062\n",
      "epoch 120 valid | Loss: 0.0296\n",
      "epoch 130 train | Loss: 0.3918\n",
      "epoch 130 valid | Loss: 0.0312\n",
      "epoch 140 train | Loss: 0.3866\n",
      "epoch 140 valid | Loss: 0.0273\n",
      "epoch 150 train | Loss: 0.3660\n",
      "epoch 150 valid | Loss: 0.0272\n",
      "epoch 160 train | Loss: 0.3815\n",
      "epoch 160 valid | Loss: 0.0256\n",
      "Early Stopping at epoch 167 with valid loss 0.0231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff32185a6c1d4e1caec99dc2c2e99f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.015 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.133058…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>167</td></tr><tr><td>train_loss</td><td>0.36555</td></tr><tr><td>valid_loss</td><td>0.02654</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MLP-regression</strong> at: <a href='https://wandb.ai/33h002/public/runs/mfifz7a4' target=\"_blank\">https://wandb.ai/33h002/public/runs/mfifz7a4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230403_131534-mfifz7a4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(name=RUN_NAME, project=WANDB_PRJ, config=WANDB_CONFIG, reinit=True) # connect\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'model running on {device}')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "min_loss = np.Inf\n",
    "trials = 0\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    running_log = {'epoch': e+1} # logging\n",
    "    \n",
    "    for phase in ['train', 'valid']: \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        model.train() if phase == 'train' else model.eval()\n",
    "\n",
    "        for idx, (features, labels) in enumerate(dataloaders[phase]):\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            with torch.set_grad_enabled(phase=='train'):\n",
    "                # forward\n",
    "                with autocast():\n",
    "                    logits = model(features)\n",
    "                    loss = criterion(logits.view(-1), labels)  \n",
    "                    \n",
    "                # backward\n",
    "                if phase == 'train' and 'cuda' in device:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                elif phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                running_loss += loss.item() * features.size(0)\n",
    "                             \n",
    "        if phase == 'train' and e >= 10:\n",
    "            scheduler.step()\n",
    "    \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        running_log.update({f'{phase}_loss': epoch_loss}) # logging\n",
    "        \n",
    "        if (e+1) % 10 == 0: \n",
    "            print(f'epoch {e+1} {phase} | Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # save best model\n",
    "        if phase == 'valid':\n",
    "            if epoch_loss < min_loss:\n",
    "                torch.save(model.state_dict(), f'{SAVE_PATH}/{RUN_NAME}-best.pt')\n",
    "                min_loss = epoch_loss\n",
    "                trials = 0\n",
    "            else:\n",
    "                trials += 1  \n",
    "                \n",
    "    wandb.log(running_log) # logging\n",
    "    \n",
    "    # early stopping\n",
    "    if trials >= PATIENCE:\n",
    "        print(f'Early Stopping at epoch {e+1} with valid loss {min_loss:.4f}')\n",
    "        break\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
